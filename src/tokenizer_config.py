# TOKENIZER 
model = "sp"
tokenizer_dataset_path = "../clean_data/source/tokenizer_dataset.txt"  # trainset for the tokenizer
tokenizer_path = "../clean_data/tokenizer/"
vocab_size = 8700